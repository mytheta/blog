---
layout: single
title: 特徴ベクトル
categories: 機械学習
tags:
 - パターン認識
 - 機械学習
paginate: true
image: /assets/images/hakone.jpg
toc: true
toc_label: "My Table of Contents"
author_profile: true
---

# 特徴ベクトルと特徴空間
## 特徴ベクトル
前回説明したように，特徴抽出部では源パターンから識別に必要な本質的な特徴のみを抽出する．しかし，**特徴**というものは様々．文字認識の場合は，文字線の傾き，幅，曲率，面積，ループの数などなど..各々の特徴は，数値化され，それらを組にしたベクトルが用いられる．

ここで，d個の特徴を用いると，パターンは地次式のようなd次元ベクトルｘとして，表される．tは転置ですね．


$$  x = (x_1,x_2,...,x_d)^t $$

このベクトルを**特徴ベクトル**，特徴ベクトルによって張られる空間を，**特徴空間**と呼ぶ．

![image](https://mytheta.github.io/blog/assets/images/vector.png)

したがって，パターンは，上の図のように1点で表される．また，対象としているクラスの総数を _c_ とし，各クラスを $$ w_1,w_2,w_3,...,w_c $$ で表す．同じクラスに属するパターンは類似しているはずであるので，クラスごとにまとまった塊に属するはずである．この塊を**クラスタ**と呼ぶ．
